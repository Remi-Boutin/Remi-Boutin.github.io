x---
---

@article{boutin2023deep,
	title={The Deep Latent Position Topic Model for Clustering and Representation of Networks with Textual Edges},
	author={Boutin, R{\'e}mi and Latouche, Pierre and Bouveyron, Charles},
	journal={arXiv preprint arXiv:2304.08242},
	year={2023},
	selected={true},
	preview={deeplptm-image.png},
	url={https://hal.science/hal-04068665},
	arxiv={2304.08242},
	hal={https://hal.science/hal-04068665},
	bibtex_show={true},
	abstract={Numerical interactions leading to users sharing textual content published by others are naturally represented by a network where the individuals are associated with the nodes and the exchanged texts with the edges. To understand those heterogeneous and complex data structures, clustering nodes into homogeneous groups as well as rendering a comprehensible visualisation of the data is mandatory. To address both issues, we introduce Deep-LPTM, a model-based clustering strategy relying on a variational graph auto-encoder approach as well as a probabilistic model to characterise the topics of discussion. Deep-LPTM allows to build a joint representation of the nodes and of the edges in two embeddings spaces. The parameters are inferred using a variational inference algorithm. We also introduce IC2L, a model selection criterion specifically designed to choose models with relevant clustering and visualisation properties. An extensive benchmark study on synthetic data is provided. In particular, we find that Deep-LPTM better recovers the partitions of the nodes than the state-of-the art ETSBM and STBM. Eventually, the emails of the Enron company are analysed and visualisations of the results are presented, with meaningful highlights of the graph structure.}
}


@article{boutin2023embedded,
	title={Embedded topics in the stochastic block model},
	author={Boutin, R{\'e}mi and Bouveyron, Charles and Latouche, Pierre},
	journal={Statistics and Computing},
	volume={33},
	number={5},
	pages={1--20},
	year={2023},
	publisher={Springer},
	selected={true},
	preview={etsbm_image.png},
	url={https://hal.science/hal-03782528},
	html={https://link.springer.com/article/10.1007/s11222-023-10265-9},
	hal={https://hal.science/hal-03782528},
	arxiv={2209.10097},
	bibtex_show={true},
	abstract={Communication networks such as emails or social networks are now ubiquitous and their analysis has become a strategic field. In many applications, the goal is to automatically extract relevant information by looking at the nodes and their connections. Unfortunately, most of the existing methods focus on analysing the presence or absence of edges and textual data is often discarded. However, all communication networks actually come with textual data on the edges. In order to take into account this specificity, we consider in this paper networks for which two nodes are linked if and only if they share textual data. We introduce a deep latent variable model allowing embedded topics to be handled called ETSBM to simultaneously perform clustering on the nodes while modelling the topics used between the different clusters. ETSBM extends both the stochastic block model (SBM) and the embedded topic model (ETM) which are core models for studying networks and corpora, respectively. The inference is done using a variational-Bayes expectation-maximisation algorithm combined with a stochastic gradient descent. The methodology is evaluated on synthetic data and on a real world dataset.}
}